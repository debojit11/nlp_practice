{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df67adf2-bc1d-4ef6-b0fb-6ec00fadd7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dd03ed5-0fc9-4126-84d5-960136c43393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca574b1-7879-426c-879a-378da10ac714",
   "metadata": {},
   "source": [
    "**Splits it into two sentences**. This is **sentence tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e591bdcf-1949-4949-93bd-9bafb5f162c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      ".\n",
      "Hulk\n",
      "loves\n",
      "chat\n",
      "of\n",
      "delhi\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    for word in sentence:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a0fad8-4f3a-466c-961f-93d0bf51cdaa",
   "metadata": {},
   "source": [
    "**Splits sentences into words**. This is **word tokenization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a7e328-f478-47c8-ad33-2e8800b3746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f3c4782-13ee-4767-9cda-bf4c67cf5b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr.', 'Strange loves pav bhaji of mumbai.', 'Hulk loves chat of delhi']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c051e7-7848-42e8-b370-941ada0b5f7c",
   "metadata": {},
   "source": [
    "**NLTK sentence tokenizer**, isn't like spacy, doesn't tokenize properly but allows customization unlike spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1fa5684-a514-4ecf-a551-1d01dd391cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dr',\n",
       " '.',\n",
       " 'Strange',\n",
       " 'loves',\n",
       " 'pav',\n",
       " 'bhaji',\n",
       " 'of',\n",
       " 'mumbai',\n",
       " '.',\n",
       " 'Hulk',\n",
       " 'loves',\n",
       " 'chat',\n",
       " 'of',\n",
       " 'delhi']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_tokenize(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed816df-a3e8-44a5-a927-775fe37e6991",
   "metadata": {},
   "source": [
    "**NLTK word tokenizer**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
